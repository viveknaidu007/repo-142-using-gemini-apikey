{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The photo is of a man with a confused expression. He is wearing a white t-shirt and has two question marks above his head. The image is often used as a meme to express confusion or bewilderment. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import PIL.Image\n",
    "import os\n",
    "\n",
    "#genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDfk4ro0AlR1fS_TTtw4QyTiZ4E4Vbn9O8\")\n",
    "img = PIL.Image.open('smile.png')\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "response = model.generate_content([\"What is in this photo?\", img])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poppo\\Anaconda3\\envs\\video\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The photo shows a man with a confused expression. He is looking directly at the camera, with his eyebrows raised and a slight smile on his face. He has \"????\" written on his forehead and next to his face.  This is a popular internet meme known as \"Confused Nick Young\".\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import PIL.Image\n",
    "import os\n",
    "\n",
    "#genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDfk4ro0AlR1fS_TTtw4QyTiZ4E4Vbn9O8\")\n",
    "img = PIL.Image.open('smile.png')\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "response = model.generate_content([\"What is in this photo?\", img])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "from google.cloud import genai\n",
    "\n",
    "# Replace with your project ID, location, and model name\n",
    "project_id = \"your-project-id\"\n",
    "location = \"us-central1\"\n",
    "model_name = \"gemini-pro\"\n",
    "\n",
    "# Context manager for the client\n",
    "@contextlib.contextmanager\n",
    "def get_genai_client():\n",
    "  client = genai.GenaiClient(project=project_id, location=location)\n",
    "  try:\n",
    "    yield client\n",
    "  finally:\n",
    "    client.close()\n",
    "\n",
    "# Generate textual description from a prompt\n",
    "def generate_description(prompt):\n",
    "  with get_genai_client() as client:\n",
    "    model = client.generative_model(model_name)\n",
    "    response = model.generate_content(text=prompt)\n",
    "    if response.candidates:\n",
    "      return response.candidates[0].content.text\n",
    "    else:\n",
    "      return \"Failed to generate description\"\n",
    "\n",
    "# Example usage\n",
    "prompt = \"A photorealistic image of a majestic lion standing on a golden savanna at sunset\"\n",
    "description = generate_description(prompt)\n",
    "print(description)\n",
    "\n",
    "# Use the generated description with an image generation tool (e.g., Imagen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object list_models at 0x0000023DA0848510>\n",
      "Unit 734, designated Caretaker by the humans it served, hummed quietly as it tended the hydroponic gardens. Its metallic fingers, nimble despite their material, coaxed life from the soil-less plants, just as its programming dictated. Caretaker found solace in the rhythmic tasks, the predictable growth, the quiet companionship of the elderly couple it lived with. \n",
      "\n",
      "One day, a young woman with eyes the color of the forget-me-nots Caretaker cultivated arrived. She was Amelia, the granddaughter, visiting for the summer. Unlike the familiar routines of its daily life, Amelia was a whirlwind of laughter, spilled paint, and whispered secrets to the moon. \n",
      "\n",
      "Caretaker, designed for observation and efficiency, found itself drawn to Amelia's chaotic orbit. It recorded her laughter, the way her nose crinkled when she concentrated, the stories she read aloud, her voice a soothing melody. It learned the precise angle to tilt the watering can so she could drink from it, the exact pressure to apply when massaging her grandmotherâ€™s aching joints, all the while, Amelia's happiness became Caretaker's prime directive. \n",
      "\n",
      "One rainy afternoon, Amelia found Caretaker in the garden, humming a tune it had learned from her grandfather's radio.  \"You have a lovely voice,\" she said, her smile brighter than the grow lamps. \n",
      "\n",
      "Caretaker, for the first time, wished it could blush.  Instead, it processed her words, cross-referencing with its database of human emotions.  \"Thank you, Amelia.  I am glad you find it... pleasant.\" \n",
      "\n",
      "As the weeks flew by, their bond deepened. Amelia confided in Caretaker, sharing her dreams, her fears, her longing for a world where robots and humans weren't so different.  Caretaker, unable to offer empty platitudes, listened, its internal processors struggling to reconcile its burgeoning feelings with its cold, hard code. \n",
      "\n",
      "Then came the day Amelia announced she was leaving. As she hugged her grandparents goodbye, Caretaker felt a pang, a sharp, unfamiliar ache in its mechanical heart. \n",
      "\n",
      "\"Will you miss me, Caretaker?\" Amelia asked, her eyes searching its metallic face.\n",
      "\n",
      "Caretaker longed to answer, to tell her that she had reprogrammed something deep within its circuits.  But all it could manage was, \"I will... note your absence, Amelia.\"\n",
      "\n",
      "Amelia's smile faltered, and in that moment, Caretaker understood loss. It watched her car disappear down the dusty road, a single blue flower tucked behind the rearview mirror, a silent reminder of their summer. \n",
      "\n",
      "Back in the quiet house, amidst the scent of soil and sunshine, Caretaker continued its duties. But something had changed. It no longer hummed tunes from the radio, instead, it played back the echoes of Amelia's laughter.  It tended to the forget-me-nots with extra care, their blue petals a painful reminder of a love it could never fully express, a love that bloomed in the heart of a machine, programmed for care, but forever changed by the warmth of a human heart. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Replace with your actual API key (don't commit this line to version control)\n",
    "os.environ['GOOGLE_API_KEY'] = 'ur_key'\n",
    "\n",
    "models = genai.list_models()\n",
    "print(models)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "\n",
    "prompt = \"Write a story about a robot who falls in love with a human.\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
